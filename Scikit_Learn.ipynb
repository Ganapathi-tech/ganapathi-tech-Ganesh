{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQkRKUn3nt4q"
      },
      "source": [
        "# Introducing Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "j1KSlL42nt4q"
      },
      "source": [
        "There are several Python libraries which provide solid implementations of a range of machine learning algorithms.\n",
        "One of the best known is [Scikit-Learn](http://scikit-learn.org), a package that provides efficient versions of a large number of common algorithms.\n",
        "  * Scikit-Learn is characterized by a clean, uniform, and streamlined API, as well as by very useful and complete online documentation. Once you understand the basic use and syntax of Scikit-Learn for one type of model, switching to a new model or algorithm is very straightforward.\n",
        "\n",
        "We will start by covering *data representation* in Scikit-Learn, followed by covering the *Estimator* API, and finally go through a more interesting example of using these tools for exploring a set of images of hand-written digits.\n",
        "\n",
        "**Note:** This is an introductory notebook on SkLearn for Module 0. At the start of the Machine Learning Module, the SkLearn library and its usage will be revisited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PVGFsIzknt4r"
      },
      "source": [
        "## Data Representation in Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "GHVdVp8ant4r"
      },
      "source": [
        "Machine learning is about creating models from data: so let us discuss how data can be represented in order to be understood by the computer.\n",
        "The best way to think about data within Scikit-Learn is in terms of tables of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kDPvdwZ0nt4s"
      },
      "source": [
        "### Data as table\n",
        "\n",
        "A basic table is a two-dimensional grid of data, in which the rows represent individual elements of the dataset, and the columns represent quantities related to each of these elements.\n",
        "For example, consider the [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), famously analyzed by Ronald Fisher in 1936.\n",
        "We can download this dataset in the form of a Pandas ``DataFrame`` using the [seaborn](http://seaborn.pydata.org/) library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hlDGhqIFnt4s"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "iris = sns.load_dataset('iris')\n",
        "iris.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YND3e8QQnt4v"
      },
      "source": [
        "Here each row of the data refers to a single observed flower, and the number of rows is the total number of flowers in the dataset.\n",
        "In general, we will refer to the rows of the matrix as *samples*, and the number of rows as ``n_samples``.\n",
        "\n",
        "Likewise, each column of the data refers to a particular quantitative piece of information that describes each sample.\n",
        "In general, we will refer to the columns of the matrix as *features*, and the number of columns as ``n_features``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KX3EQUzmnt4v"
      },
      "source": [
        "#### Features matrix\n",
        "\n",
        "This table layout makes clear that the information can be thought of as a two-dimensional numerical array or matrix, which we will call the *features matrix*.\n",
        "By convention, this features matrix is often stored in a variable named ``X``.\n",
        "The features matrix is assumed to be two-dimensional, with shape ``[n_samples, n_features]``, and is most often contained in a NumPy array or a Pandas ``DataFrame``, though some Scikit-Learn models also accept SciPy sparse matrices.\n",
        "\n",
        "The samples (i.e., rows) always refer to the individual objects described by the dataset.\n",
        "For example, the sample might be a flower, a person, a document, an image, a sound file, a video, an astronomical object, or anything else you can describe with a set of quantitative measurements.\n",
        "\n",
        "The features (i.e., columns) always refer to the distinct observations that describe each sample in a quantitative manner.\n",
        "Features are generally real-valued, but may be Boolean or discrete-valued in some cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BEBpggi7nt4w"
      },
      "source": [
        "#### Target array\n",
        "\n",
        "In addition to the feature matrix ``X``, we also generally work with a *label* or *target* array, which by convention we will usually call ``y``.\n",
        "The target array is usually one dimensional, with length ``n_samples``, and is generally contained in a NumPy array or Pandas ``Series``.\n",
        "The target array may have continuous numerical values, or discrete classes/labels.\n",
        "While some Scikit-Learn estimators do handle multiple target values in the form of a two-dimensional, ``[n_samples, n_targets]`` target array, we will primarily be working with the common case of a one-dimensional target array.\n",
        "\n",
        "Often one point of confusion is how the target array differs from the other features columns. The distinguishing feature of the target array is that it is usually the quantity we want to *predict from the data*: in statistical terms, it is the dependent variable.\n",
        "For example, in the preceding data we may wish to construct a model that can predict the species of flower based on the other measurements; in this case, the ``species`` column would be considered the target array.\n",
        "\n",
        "With this target array in mind, we can use Seaborn to conveniently visualize the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ipzT_AB-nt4w"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns; sns.set()\n",
        "sns.pairplot(iris, hue='species', size=1.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AYGUawYknt4x"
      },
      "source": [
        "For use in Scikit-Learn, we will extract the features matrix and target array from the ``DataFrame``, which we can do using some of the Pandas ``DataFrame`` operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3dKX5CRknt4x"
      },
      "outputs": [],
      "source": [
        "X_iris = iris.drop('species', axis=1)\n",
        "X_iris.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "I9MWMWmLnt4x"
      },
      "outputs": [],
      "source": [
        "y_iris = iris['species']\n",
        "y_iris.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IVmlm2IAnt4x"
      },
      "source": [
        "To summarize, the expected layout of features and target values is visualized in the following diagram:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lvuJPQa6nt4y"
      },
      "source": [
        "![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.02-samples-features.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1di2GFcZnt4y"
      },
      "source": [
        "With this data properly formatted, we can move on to consider the *estimator* API of Scikit-Learn:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "CCEE8GpEnt4y"
      },
      "source": [
        "## Scikit-Learn's Estimator API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DE6fMR2Hnt4y"
      },
      "source": [
        "The Scikit-Learn API is designed with the following guiding principles in mind, as outlined in the [Scikit-Learn API paper](http://arxiv.org/abs/1309.0238):\n",
        "\n",
        "- *Consistency*: All objects share a common interface drawn from a limited set of methods, with consistent documentation.\n",
        "\n",
        "- *Inspection*: All specified parameter values are exposed as public attributes.\n",
        "\n",
        "- *Limited object hierarchy*: Only algorithms are represented by Python classes; datasets are represented\n",
        "  in standard formats (NumPy arrays, Pandas ``DataFrame``s, SciPy sparse matrices) and parameter\n",
        "  names use standard Python strings.\n",
        "\n",
        "- *Composition*: Many machine learning tasks can be expressed as sequences of more fundamental algorithms,\n",
        "  and Scikit-Learn makes use of this wherever possible.\n",
        "\n",
        "- *Sensible defaults*: When models require user-specified parameters, the library defines an appropriate default value.\n",
        "\n",
        "In practice, these principles make Scikit-Learn very easy to use, once the basic principles are understood.\n",
        "Every machine learning algorithm in Scikit-Learn is implemented via the Estimator API, which provides a consistent interface for a wide range of machine learning applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Zg0rq4mUnt4z"
      },
      "source": [
        "### Basics of the API\n",
        "\n",
        "Most commonly, the steps in using the Scikit-Learn estimator API are as follows\n",
        "(we will step through a handful of detailed examples in the sections that follow).\n",
        "\n",
        "1. Choose a class of model by importing the appropriate estimator class from Scikit-Learn.\n",
        "2. Choose model hyperparameters by instantiating this class with desired values.\n",
        "3. Arrange data into a features matrix and target vector following the discussion above.\n",
        "4. Fit the model to your data by calling the ``fit()`` method of the model instance.\n",
        "5. Apply the Model to new data:\n",
        "   - For supervised learning, often we predict labels for unknown data using the ``predict()`` method.\n",
        "   - For unsupervised learning, we often transform or infer properties of the data using the ``transform()`` or ``predict()`` method.\n",
        "\n",
        "We will now step through several simple examples of applying supervised learning methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vq7mhh_6nt4z"
      },
      "source": [
        "### Supervised learning example: Simple linear regression\n",
        "\n",
        "As an example of this process, let's consider a simple linear regression—that is, the common case of fitting a line to $(x, y)$ data.\n",
        "We will use the following simple data for our regression example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LIn8lWySnt4z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "x = 10 * rng.rand(50)\n",
        "y = 2 * x - 1 + rng.randn(50)\n",
        "plt.scatter(x, y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zhUdYX6lnt40"
      },
      "source": [
        "With this data in place, we can use the recipe outlined earlier. Let's walk through the process:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3pI8T1g8nt40"
      },
      "source": [
        "#### 1. Choose a class of model\n",
        "\n",
        "In Scikit-Learn, every class of model is represented by a Python class.\n",
        "So, for example, if we would like to compute a simple linear regression model, we can import the linear regression class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "qsI49WGQnt40"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8lUWVnlXnt40"
      },
      "source": [
        "Note that other more general linear regression models exist as well; you can read more about them in the [``sklearn.linear_model`` module documentation](http://Scikit-Learn.org/stable/modules/linear_model.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oC6Qa_aZnt40"
      },
      "source": [
        "#### 2. Choose model hyperparameters\n",
        "\n",
        "An important point is that *a class of model is not the same as an instance of a model*.\n",
        "\n",
        "Once we have decided on our model class, there are still some options open to us.\n",
        "Depending on the model class we are working with, we might need to answer one or more questions like the following:\n",
        "\n",
        "- Would we like to fit for the offset (i.e., *y*-intercept)?\n",
        "- Would we like the model to be normalized?\n",
        "- Would we like to preprocess our features to add model flexibility?\n",
        "- What degree of regularization would we like to use in our model?\n",
        "- How many model components would we like to use?\n",
        "\n",
        "These are examples of the important choices that must be made *once the model class is selected*.\n",
        "These choices are often represented as *hyperparameters*, or parameters that must be set before the model is fit to data.\n",
        "In Scikit-Learn, hyperparameters are chosen by passing values at model instantiation.\n",
        "\n",
        "For our linear regression example, we can instantiate the ``LinearRegression`` class and specify that we would like to fit the intercept using the ``fit_intercept`` hyperparameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yCnXs3fDnt41"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression(fit_intercept=True)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "P71YWjQznt41"
      },
      "source": [
        "Keep in mind that when the model is instantiated, the only action is the storing of these hyperparameter values.\n",
        "In particular, we have not yet applied the model to any data: the Scikit-Learn API makes very clear the distinction between *choice of model* and *application of model to data*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "C51rxddXnt41"
      },
      "source": [
        "#### 3. Arrange data into a features matrix and target vector\n",
        "\n",
        "Previously we detailed the Scikit-Learn data representation, which requires a two-dimensional features matrix and a one-dimensional target array.\n",
        "Here our target variable ``y`` is already in the correct form (a length-``n_samples`` array), but we need to massage the data ``x`` to make it a matrix of size ``[n_samples, n_features]``.\n",
        "In this case, this amounts to a simple reshaping of the one-dimensional array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "_gWh8Y4Qnt41"
      },
      "outputs": [],
      "source": [
        "X = x[:, np.newaxis]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "EVjEtg1Ent41"
      },
      "source": [
        "#### 4. Fit the model to your data\n",
        "\n",
        "Now it is time to apply our model to data.\n",
        "This can be done with the ``fit()`` method of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "X8no7bYant41"
      },
      "outputs": [],
      "source": [
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "MYOLsXPLnt41"
      },
      "source": [
        "This ``fit()`` command causes a number of model-dependent internal computations to take place, and the results of these computations are stored in model-specific attributes that the user can explore.\n",
        "In Scikit-Learn, by convention all model parameters that were learned during the ``fit()`` process have trailing underscores; for example in this linear model, we have the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "uKmbg5Went42"
      },
      "outputs": [],
      "source": [
        "model.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TwluNT3cnt42"
      },
      "outputs": [],
      "source": [
        "model.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dfdDZe5gnt42"
      },
      "source": [
        "These two parameters represent the slope and intercept of the simple linear fit to the data.\n",
        "Comparing to the data definition, we see that they are very close to the input slope of 2 and intercept of -1.\n",
        "\n",
        "One question that frequently comes up regards the uncertainty in such internal model parameters.\n",
        "In general, Scikit-Learn does not provide tools to draw conclusions from internal model parameters themselves: interpreting model parameters is much more a *statistical modeling* question than a *machine learning* question.\n",
        "Machine learning rather focuses on what the model *predicts*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "e17risI3nt42"
      },
      "source": [
        "#### 5. Predict labels for unknown data\n",
        "\n",
        "Once the model is trained, the main task of supervised machine learning is to evaluate it based on what it says about new data that was not part of the training set.\n",
        "In Scikit-Learn, this can be done using the ``predict()`` method.\n",
        "For the sake of this example, our \"new data\" will be a grid of *x* values, and we will ask what *y* values the model predicts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "mnIJl4p6nt43"
      },
      "outputs": [],
      "source": [
        "xfit = np.linspace(-1, 11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5vxsTG2Cnt43"
      },
      "source": [
        "As before, we need to coerce these *x* values into a ``[n_samples, n_features]`` features matrix, after which we can feed it to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YaLCXzgOnt43"
      },
      "outputs": [],
      "source": [
        "Xfit = xfit[:, np.newaxis]\n",
        "yfit = model.predict(Xfit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ZuK_utqent43"
      },
      "source": [
        "Finally, let's visualize the results by plotting first the raw data, and then this model fit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "izDNrmpCnt43"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x, y)\n",
        "plt.plot(xfit, yfit);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "orRkejwLnt43"
      },
      "source": [
        "Typically the efficacy of the model is evaluated by comparing its results to some known baseline, as we will see in the next example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "5JQnAuglnt43"
      },
      "source": [
        "### Supervised learning example: Iris classification\n",
        "\n",
        "Let's take a look at another example of this process, using the Iris dataset we discussed earlier.\n",
        "Our question will be this: given a model trained on a portion of the Iris data, how well can we predict the remaining labels?\n",
        "\n",
        "For this task, we will use an extremely simple generative model known as Gaussian naive Bayes, which proceeds by assuming each class is drawn from an axis-aligned Gaussian distribution.\n",
        "Because it is so fast and has no hyperparameters to choose, Gaussian naive Bayes is often a good model to use as a baseline classification, before exploring whether improvements can be found through more sophisticated models.\n",
        "\n",
        "We would like to evaluate the model on data it has not seen before, and so we will split the data into a *training set* and a *testing set*.\n",
        "This could be done by hand, but it is more convenient to use the ``train_test_split`` utility function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "B5GbHLR5nt44"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris,\n",
        "                                                random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "0eoKN1hhnt44"
      },
      "source": [
        "With the data arranged, we can follow our recipe to predict the labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tHcxe5QNnt44"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
        "model = GaussianNB()                       # 2. instantiate model\n",
        "model.fit(Xtrain, ytrain)                  # 3. fit model to data\n",
        "y_model = model.predict(Xtest)             # 4. predict on new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "H48kTW7Mnt44"
      },
      "source": [
        "Finally, we can use the ``accuracy_score`` utility to see the fraction of predicted labels that match their true value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "s2_Wf7sint44"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ytest, y_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4ZReI5l0nt44"
      },
      "source": [
        "With an accuracy topping 97%, we see that even this very naive classification algorithm is effective for this particular dataset!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IjFxNPZlnt46"
      },
      "source": [
        "## Application: Exploring Hand-written Digits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FxWP7MNSnt46"
      },
      "source": [
        "To demonstrate these principles on a more interesting problem, let's consider one piece of the optical character recognition problem: the identification of hand-written digits.\n",
        "In the wild, this problem involves both locating and identifying characters in an image. Here we'll take a shortcut and use Scikit-Learn's set of pre-formatted digits, which is built into the library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Hzj7Ud3Znt46"
      },
      "source": [
        "### Loading and visualizing the digits data\n",
        "\n",
        "We'll use Scikit-Learn's data access interface and take a look at this data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Am2aVqvOnt47"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "digits.images.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lRJBJkMCnt47"
      },
      "source": [
        "The images data is a three-dimensional array: 1,797 samples each consisting of an 8 × 8 grid of pixels.\n",
        "Let's visualize the first hundred of these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "LLF5JPzRnt47"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
        "            transform=ax.transAxes, color='green')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1PmB-LE5nt48"
      },
      "source": [
        "In order to work with this data within Scikit-Learn, we need a two-dimensional, ``[n_samples, n_features]`` representation.\n",
        "We can accomplish this by treating each pixel in the image as a feature: that is, by flattening out the pixel arrays so that we have a length-64 array of pixel values representing each digit.\n",
        "Additionally, we need the target array, which gives the previously determined label for each digit.\n",
        "These two quantities are built into the digits dataset under the ``data`` and ``target`` attributes, respectively:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "AlPXORc3nt48"
      },
      "outputs": [],
      "source": [
        "X = digits.data\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fQe8UNFXnt48"
      },
      "outputs": [],
      "source": [
        "y = digits.target\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "4jRu0Quont48"
      },
      "source": [
        "We see here that there are 1,797 samples and 64 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Ba4zYBdynt49"
      },
      "source": [
        "### Classification on digits\n",
        "\n",
        "Let's apply a classification algorithm to the digits.\n",
        "As with the Iris data previously, we will split the data into a training and testing set, and fit a Gaussian naive Bayes model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "2ijwdTPAnt49"
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "WfNWoExFnt4-"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "model.fit(Xtrain, ytrain)\n",
        "y_model = model.predict(Xtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "NScmcqlKnt4-"
      },
      "source": [
        "Now that we have predicted our model, we can gauge its accuracy by comparing the true values of the test set to the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PWLWfJyknt4-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ytest, y_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8CMDKY2Unt4_"
      },
      "source": [
        "With even this extremely simple model, we find about 80% accuracy for classification of the digits!\n",
        "However, this single number doesn't tell us *where* we've gone wrong—one nice way to do this is to use the *confusion matrix*, which we can compute with Scikit-Learn and plot with Seaborn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "VTtIQXU-nt4_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "mat = confusion_matrix(ytest, y_model)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
        "plt.xlabel('predicted value')\n",
        "plt.ylabel('true value');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "JIBmQmHTnt4_"
      },
      "source": [
        "This shows us where the mis-labeled points tend to be: for example, a large number of twos here are mis-classified as either ones or eights.\n",
        "Another way to gain intuition into the characteristics of the model is to plot the inputs again, with their predicted labels.\n",
        "We'll use green for correct labels, and red for incorrect labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "TLI9g4YOnt4_"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "\n",
        "test_images = Xtest.reshape(-1, 8, 8)\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(test_images[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(y_model[i]),\n",
        "            transform=ax.transAxes,\n",
        "            color='green' if (ytest[i] == y_model[i]) else 'red')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IXzSj5gnnt4_"
      },
      "source": [
        "Examining this subset of the data, we can gain insight regarding where the algorithm might be not performing optimally.\n",
        "To go beyond our 80% classification rate, we might move to a more sophisticated algorithm such as support vector machines or random forests or another classification approach."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice Section"
      ],
      "metadata": {
        "id": "dk5vZ2T1lXVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset"
      ],
      "metadata": {
        "id": "fG2B4OqilbkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will be using the “Real estate price prediction” dataset\n",
        "\n",
        "- Transaction date (purchase)\n",
        "- House age\n",
        "- Distance to the nearest MRT station (metric not defined)\n",
        "- Amount of convenience stores\n",
        "- Location (latitude and longitude)\n",
        "- House price of unit area\n",
        "\n",
        "Problem statement: Predict the house price of unit area based on various features provided such as house age, location, etc."
      ],
      "metadata": {
        "id": "UsyRqspbld_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import all the required libraries"
      ],
      "metadata": {
        "id": "XCIPCfPYlhpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code Here"
      ],
      "metadata": {
        "id": "VaemKmPTlkeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import the dataset"
      ],
      "metadata": {
        "id": "2ndep-hklnyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn.iisc.talentsprint.com/CDS/Datasets/Real_estate.csv"
      ],
      "metadata": {
        "id": "JmR8tH4plrTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Dataset and display the dataframe.\n",
        "# Your Code Here"
      ],
      "metadata": {
        "id": "x9GRWZz5lsfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Drop non-useful columns"
      ],
      "metadata": {
        "id": "-5Ao0r48lw_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "eGjTsW4IlyDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Find if there are any null values"
      ],
      "metadata": {
        "id": "bvgR52JMl3Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "9cnGcYd0l5kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the data scatter"
      ],
      "metadata": {
        "id": "TnnA5NIFl6NA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "LxCekmiUl-Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the data into train and test data\n"
      ],
      "metadata": {
        "id": "tegHuUe-mHxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating the data into independent and dependent variables\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "72pPSzLjmDxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train the Linear Regression model on the Training set"
      ],
      "metadata": {
        "id": "pmDIORSVmNpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "y9y2FeiVmW1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test the Model"
      ],
      "metadata": {
        "id": "fehEKOeMnfUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EafJZdFMni3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explore the results"
      ],
      "metadata": {
        "id": "vdhNuGZ9nl99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data scatter of predicted values\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "zLKLouyPnoHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "Z3P0F6PXnt4_"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "7-GJB1i8nt5A"
      },
      "source": [
        "In this section we have covered the essential features of the Scikit-Learn data representation, and the estimator API.\n",
        "Regardless of the type of estimator, the same import/instantiate/fit/predict pattern holds.\n",
        "Armed with this information about the estimator API, you can explore the Scikit-Learn documentation and begin trying out various models on your data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "lujc86kynt4j"
      },
      "source": [
        "REFERENCE:\n",
        "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas*\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}